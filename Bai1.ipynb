{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 cuisine  almond  angelica  anise  anise_seed  apple  \\\n",
       "0          65  indian       0         0      0           0      0   \n",
       "1          66  indian       1         0      0           0      0   \n",
       "2          67  indian       0         0      0           0      0   \n",
       "3          68  indian       0         0      0           0      0   \n",
       "4          69  indian       0         0      0           0      0   \n",
       "\n",
       "   apple_brandy  apricot  armagnac  ...  whiskey  white_bread  white_wine  \\\n",
       "0             0        0         0  ...        0            0           0   \n",
       "1             0        0         0  ...        0            0           0   \n",
       "2             0        0         0  ...        0            0           0   \n",
       "3             0        0         0  ...        0            0           0   \n",
       "4             0        0         0  ...        0            0           0   \n",
       "\n",
       "   whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "0                        0     0     0    0      0       0         0  \n",
       "1                        0     0     0    0      0       0         0  \n",
       "2                        0     0     0    0      0       0         0  \n",
       "3                        0     0     0    0      0       0         0  \n",
       "4                        0     0     0    0      0       1         0  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = pd.read_csv('asian_indian_recipes.csv')\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>artemisia</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cuisine  almond  angelica  anise  anise_seed  apple  apple_brandy  apricot  \\\n",
       "0  indian       0         0      0           0      0             0        0   \n",
       "1  indian       1         0      0           0      0             0        0   \n",
       "2  indian       0         0      0           0      0             0        0   \n",
       "3  indian       0         0      0           0      0             0        0   \n",
       "4  indian       0         0      0           0      0             0        0   \n",
       "\n",
       "   armagnac  artemisia  ...  whiskey  white_bread  white_wine  \\\n",
       "0         0          0  ...        0            0           0   \n",
       "1         0          0  ...        0            0           0   \n",
       "2         0          0  ...        0            0           0   \n",
       "3         0          0  ...        0            0           0   \n",
       "4         0          0  ...        0            0           0   \n",
       "\n",
       "   whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "0                        0     0     0    0      0       0         0  \n",
       "1                        0     0     0    0      0       0         0  \n",
       "2                        0     0     0    0      0       0         0  \n",
       "3                        0     0     0    0      0       0         0  \n",
       "4                        0     0     0    0      0       1         0  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = recipes.iloc[:,1:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>artemisia</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine  almond  angelica  anise  anise_seed  apple  apple_brandy  \\\n",
       "2443  japanese       0         0      0           0      0             0   \n",
       "2444  japanese       0         0      0           0      0             0   \n",
       "2445  japanese       0         0      0           0      0             0   \n",
       "2446  japanese       0         0      0           0      0             0   \n",
       "2447  japanese       0         0      0           0      0             0   \n",
       "\n",
       "      apricot  armagnac  artemisia  ...  whiskey  white_bread  white_wine  \\\n",
       "2443        0         0          0  ...        0            0           0   \n",
       "2444        0         0          0  ...        0            0           0   \n",
       "2445        0         0          0  ...        0            0           0   \n",
       "2446        0         0          0  ...        0            0           0   \n",
       "2447        0         0          0  ...        0            0           0   \n",
       "\n",
       "      whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "2443                        0     0     0    0      0       0         0  \n",
       "2444                        0     0     0    0      0       0         0  \n",
       "2445                        0     0     0    0      0       0         0  \n",
       "2446                        0     0     0    0      0       0         0  \n",
       "2447                        0     0     0    0      0       0         0  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2448 entries, 0 to 2447\n",
      "Columns: 384 entries, cuisine to zucchini\n",
      "dtypes: int64(383), object(1)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, em thấy dữ liệu là tất cả các cột đều là category, và không có một ô dữ liệu nào missing value hết. Nên em tiến hành các bước xem số lượng mỗi loại cho target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>almond</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          almond\n",
       "cuisine         \n",
       "chinese      442\n",
       "indian       598\n",
       "japanese     320\n",
       "korean       799\n",
       "thai         289"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.groupby('cuisine').count()\n",
    "number = df.iloc[:,0:1]\n",
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.bar(number.index,number.almond)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy số lượng mẫu khá cân bằng ở các loại, mặc dù vẫn còn chêch lệch giữa 799 và 289, nhưng vẫn chấp nhận được."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cắt dữ liệu ra tập train và test: Em cắt dữ liệu 7:3 và áp dụng random forest trước, xem xét rồi sau đó mới áp dụng chỉnh tham số, kfold, grid search, random search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:,1:]\n",
    "Y = data['cuisine']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>artemisia</th>\n",
       "      <th>artichoke</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 383 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      almond  angelica  anise  anise_seed  apple  apple_brandy  apricot  \\\n",
       "1453       0         0      0           0      0             0        0   \n",
       "59         0         0      0           0      0             0        0   \n",
       "978        0         0      0           0      0             0        0   \n",
       "2263       0         0      0           0      0             0        0   \n",
       "207        0         0      0           0      0             0        0   \n",
       "\n",
       "      armagnac  artemisia  artichoke  ...  whiskey  white_bread  white_wine  \\\n",
       "1453         0          0          0  ...        0            0           0   \n",
       "59           0          0          0  ...        0            0           0   \n",
       "978          0          0          0  ...        0            0           0   \n",
       "2263         0          0          0  ...        0            0           1   \n",
       "207          0          0          0  ...        0            0           0   \n",
       "\n",
       "      whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "1453                        0     0     0    0      0       0         0  \n",
       "59                          0     0     0    0      0       0         0  \n",
       "978                         0     0     0    0      0       0         0  \n",
       "2263                        0     0     0    0      0       0         0  \n",
       "207                         0     0     0    0      0       0         0  \n",
       "\n",
       "[5 rows x 383 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model = model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054421768707483"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054421768707483"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997081144191477"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bước đầu ta thấy Random forest hoạt động khá ổn cho bộ dữ liệu trên, độ chính xác là 80.5%, nhưng ta thấy vẫn có chêch lệch score giữa tập train và tập test. Ta phải đi tối ưu hơn mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bước này em chia train test ra 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = RandomForestClassifier(n_estimators=200)\n",
    "model_1 = model.fit(X_train_1, Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.810204081632653"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_1 = model_1.predict(X_test_1)\n",
    "accuracy_score(Y_test_1, Y_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình tăng độ chính xác là 81.0%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bước này em chọn lọc features quan trọng xem có cải thiện độ chính xác hay không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = pd.Series(model_1.feature_importances_, index = X.columns).sort_values(ascending = False)\n",
    "\n",
    "X_new = X\n",
    "\n",
    "list_of_ind = imp_features.index\n",
    "list_drop = []\n",
    "\n",
    "for i in range(imp_features.shape[0]):\n",
    "    if imp_features[i] < 0.005:\n",
    "        list_drop.append(list_of_ind[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new.drop(list_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, Y_train_2, Y_test_2 = train_test_split(X_new, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators=200)\n",
    "model_2 = model.fit(X_train_2, Y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918367346938775"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_2 = model_2.predict(X_test_2)\n",
    "accuracy_score(Y_test_2, Y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882533197139939"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.score(X_train_2, Y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918367346938775"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.score(X_test_2, Y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mặc dầu đã lọc features nhưng bài toán không cải thiện độ chính xác, nên em sẽ giữ nguyên tất cả features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chọn thuật toán tốt nhất cho bộ dữ liệu trên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83116883 0.81758958 0.83660131 0.79738562 0.81699346 0.74509804\n",
      " 0.81967213 0.77631579]\n",
      "[0.69805195 0.70358306 0.66993464 0.70261438 0.66993464 0.64052288\n",
      " 0.69180328 0.67105263]\n",
      "[0.84415584 0.82084691 0.80392157 0.79411765 0.79738562 0.71895425\n",
      " 0.80983607 0.76973684]\n",
      "[0.74350649 0.74267101 0.7254902  0.72875817 0.69934641 0.69281046\n",
      " 0.72131148 0.68421053]\n",
      "[0.80194805 0.80781759 0.80392157 0.79738562 0.78104575 0.74509804\n",
      " 0.79016393 0.75986842]\n",
      "[0.86038961 0.78827362 0.81699346 0.80392157 0.76143791 0.72875817\n",
      " 0.82622951 0.75      ]\n",
      "[0.84415584 0.80781759 0.83333333 0.80392157 0.7254902  0.73202614\n",
      " 0.81639344 0.74671053]\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LogisticRegression(solver = 'sag'),\n",
    "    DecisionTreeClassifier(criterion = 'gini'),\n",
    "    RandomForestClassifier(n_estimators=200),\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    SVC(kernel = 'linear'),\n",
    "    BernoulliNB(),\n",
    "    MultinomialNB()\n",
    "]\n",
    "\n",
    "CV = 8\n",
    "cv_df = pd.DataFrame(index = range(CV * len(models)))\n",
    "\n",
    "each_model = []\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, X, Y, scoring = 'accuracy', cv = CV)\n",
    "    print(accuracies)\n",
    "    \n",
    "    each_model.append([model_name, accuracies.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>mean of accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.805103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.680937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.794869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.717263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.785906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.788731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model name  mean of accuracy\n",
       "0      LogisticRegression          0.805103\n",
       "1  DecisionTreeClassifier          0.680937\n",
       "2  RandomForestClassifier          0.794869\n",
       "3    KNeighborsClassifier          0.717263\n",
       "4                     SVC          0.785906\n",
       "5             BernoulliNB          0.792000\n",
       "6           MultinomialNB          0.788731"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(each_model, columns = ['model name', 'mean of accuracy'])\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.bar(cv_df['model name'], cv_df['mean of accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau bước này em thấy được logistic regression for multiclass là phân loại tốt nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chọn logistic regression để làm grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-5, 5, 20),\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator = LogisticRegression(random_state = 1), param_grid = param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=1, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([1.00000e-05, 3.35982e-05, 1.12884e-04, 3.79269e-04, 1.27427e-03,\n",
       "       4.28133e-03, 1.43845e-02, 4.83293e-02, 1.62378e-01, 5.45559e-01,\n",
       "       1.83298e+00, 6.15848e+00, 2.06914e+01, 6.95193e+01, 2.33572e+02,\n",
       "       7.84760e+02, 2.63665e+03, 8.85867e+03, 2.97635e+04, 1.00000e+05]), 'solver': ['liblinear', 'saga']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.8329807108324339, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta đã chọn được bộ tham số tốt nhất cho logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = CV_rfc.best_params_['C'])\n",
    "model_3 = model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_final = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8258503401360544"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87974314068885"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8258503401360544"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Em thấy được mô hình logistic làm cho độ chính xác tăng lên 2.5% với bộ data 7:3 là 82.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Thử với 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, Y_train_3, Y_test_3 = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = CV_rfc.best_params_['C'])\n",
    "model_4 = model_4.fit(X_train_3, Y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model_4.predict(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8183673469387756"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_3, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Giảm độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Làm việc với KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8032639738882089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "model_5 = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = CV_rfc.best_params_['C'])\n",
    "kfold = KFold(n_splits = 10, random_state = 42)\n",
    "results = model_selection.cross_val_score(model_5, X_train, Y_train, cv = kfold)\n",
    "print('Accuracy: ', results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Vậy em thấy được model Logistic Regression với bộ dữ liệu 7:3 sẽ cho độ chính xác cao nhất là 82.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nhưng để chắc chắn hơn em quay lại phần chọn mô hình, em thấy Random Forest cũng có độ chính xác gần sát với logistic. Nên em sẽ dung grid search với nó để củng cố độ chính xác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100,200,300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator = RandomForestClassifier(random_state = 1), param_grid = param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [50, 100, 200, 300], 'max_features': ['auto', 'sqrt', 'log2'], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_features': 'auto', 'n_estimators': 200}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = RandomForestClassifier(criterion = 'gini', max_features = 'auto', n_estimators=200)\n",
    "model_6 = model_6.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model_6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122448979591836"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = RandomForestClassifier(criterion = 'gini', max_features = 'auto', n_estimators=200)\n",
    "model_7 = model_6.fit(X_train_1, Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model_7.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7979591836734694"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_1, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Thử Gird Search với BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': range(0,5,1),\n",
    "    'binarize': range(0,5,1),\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator = BernoulliNB(), param_grid = param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
      "c:\\users\\khang\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': range(0, 5), 'binarize': range(0, 5), 'fit_prior': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'binarize': 0, 'fit_prior': True}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8 = BernoulliNB()\n",
    "model_8.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_f = model_8.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8326530612244898"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, Y_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126094570928196"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8326530612244898"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9 = BernoulliNB()\n",
    "model_9.fit(X_train_1, Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model_8.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285714285714286"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test_1, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> KẾT LUẬN: Vậy ta thấy được Bernoulli NB (model 8) với bộ dữ liệu 7:3 là tốt nhất với độ chính xác 83.3% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** CHỌN BERNOULLI NB ***** Với ACCURACY SCORE LÀ **83.3%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Có cumin, fish, nhưng không có fish, yoghurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X[(X['cumin'] == 1) & (X['fish'] == 1) & (X['yogurt'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new = model_8.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['indian', 'thai', 'thai', 'thai', 'thai', 'thai', 'thai', 'thai',\n",
       "       'thai', 'thai', 'thai', 'thai', 'thai', 'thai', 'thai', 'thai',\n",
       "       'thai', 'thai', 'thai', 'thai', 'thai', 'thai', 'thai', 'thai',\n",
       "       'thai', 'thai', 'thai', 'thai', 'thai', 'indian', 'indian', 'thai',\n",
       "       'indian', 'thai', 'indian', 'thai', 'thai', 'thai', 'thai', 'thai',\n",
       "       'thai', 'indian', 'thai', 'thai', 'thai', 'thai', 'thai', 'thai',\n",
       "       'thai', 'thai', 'indian', 'indian'], dtype='<U8')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Vậy khi theo đa số dự đoán: các món ăn có cumin, fish, không có yogurt thì thường là món ăn Thái Lan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Có cumin, không có fish, soy_sauce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X[(X['cumin'] == 1) & (X['fish'] == 0) & (X['soy_sauce'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new = model_8.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['indian', 'indian', 'indian', 'indian', 'indian', 'thai', 'indian',\n",
       "       'indian', 'indian', 'indian', 'indian', 'indian', 'indian',\n",
       "       'indian', 'indian'], dtype='<U8')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_new[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Các món ăn có cumin, nhưng không có fish và soy_sauce thường là món ăn Ấn Độ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.80      0.79      0.80       145\n",
      "      indian       0.91      0.93      0.92       177\n",
      "    japanese       0.66      0.64      0.65        88\n",
      "      korean       0.84      0.89      0.86       229\n",
      "        thai       0.89      0.76      0.82        96\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       735\n",
      "   macro avg       0.82      0.80      0.81       735\n",
      "weighted avg       0.83      0.83      0.83       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107,   4,  11,  19,   4],\n",
       "       [  0, 165,   1,   6,   5],\n",
       "       [ 12,   2,  58,  14,   2],\n",
       "       [ 13,   1,  10, 203,   2],\n",
       "       [  8,   8,   2,   4,  74]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, Y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590909090909091"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58/(12+2+58+14+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Có 66% món ăn Nhật được đoán đúng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043668122270742356"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/(13+1+10+203+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Có 4% món ăn Hàn Quốc bị gán nhãn sai thành Nhật Bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhật Bản là nước có món ăn bị gán nhãn sai nhiều nhất (34%), vì số lượng món ăn Nhật Bản trong tập dữ liệu là ít so với các loại khác (ví dụ ở tập test nó chỉ có 88 mẫu), nên vấn đề gán nhãn sai là khó tránh khỏi. Giải pháp:\n",
    "* Thu thập thêm dữ liệu cho món ăn Nhật Bản, điều này có thể làm tăng độ chính xác lên cao hơn 83.3%\n",
    "* Cân bằng dữ liệu cho các loại, nhưng điều này có thể làm giảm độ chính xác của mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Hoặc nếu muốn chính xác hơn, ta nên dùng probability cho các mẫu được dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.29314237e-04, 2.83728950e-08, 1.64304434e-04, 9.98905191e-01,\n",
       "        1.16171387e-06],\n",
       "       [3.52562737e-03, 7.61021443e-09, 3.34351163e-04, 9.96135192e-01,\n",
       "        4.82221532e-06],\n",
       "       [2.43407900e-04, 7.04201544e-09, 7.60364896e-04, 9.98994057e-01,\n",
       "        2.16281392e-06],\n",
       "       ...,\n",
       "       [4.28610183e-06, 9.05654738e-09, 1.14358561e-08, 1.27161513e-10,\n",
       "        9.99995693e-01],\n",
       "       [3.06607433e-09, 9.98923354e-01, 5.93000436e-11, 8.98974828e-14,\n",
       "        1.07664243e-03],\n",
       "       [6.06706652e-01, 3.20854675e-08, 3.47740332e-01, 4.47064086e-02,\n",
       "        8.46575035e-04]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prob = model_8.predict_proba(X_test)\n",
    "Y_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
